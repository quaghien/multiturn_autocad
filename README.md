Read docs, papers:

https://huggingface.co/docs/accelerate/en/usage_guides/deepspeed#student-model

https://huggingface.co/docs/trl/sft_trainer

https://huggingface.co/docs/trl/data_utils

https://huggingface.co/docs/transformers/trainer#galore

https://huggingface.co/docs/trl/dataset_formats

https://huggingface.co/docs/trl/reducing_memory_usage

https://huggingface.co/datasets/TruongSinhAI/DEEPCAD-Text2Json-EnVi

https://huggingface.co/Qwen/Qwen2.5-7B-Instruct

https://github.com/jiaweizzhao/GaLore

https://github.com/SadilKhan/Text2CAD

https://github.com/ChrisWu1997/DeepCAD

[On the Thinking-Language Modeling Gap in Large Language Models](https://arxiv.org/abs/2505.12896)

[Universality of Layer-Level Entropy-Weighted Quantization Beyond Model Architecture and Size]([url](https://arxiv.org/abs/2503.04704))
